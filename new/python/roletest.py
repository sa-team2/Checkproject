from transformers import pipeline
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import torch.nn as nn
import re

# è¼‰å…¥ Hugging Face çš„ Zero-shot Learning åˆ†é¡æ¨¡å‹
classifier = pipeline("zero-shot-classification", model="./emomodel", tokenizer="./emomodel")

# æ“´å±•è©é¨™æƒ…ç·’é¡åˆ¥ - è©é¨™è€…æƒ…ç·’
scam_perpetrator_emotions = [
    "èª˜é¨™", "å¨è„…", "è©é¨™", "æ•²è©", "æ“ç¸±", "è©è¡“", 
    "èª¤å°", "æ¬ºé¨™", "è¬Šè¨€",  "æ“æ§æƒ…æ„Ÿ", "å¼·è¿«", "å¨è„…", "å‹’ç´¢", 
    "æ’’è¬Š", "éš±ç", "è™›å‡", "æ¬ºè©", "ä¸èª å¯¦", "å½è£", "ç«„æ”¹", "è²ªå¿ƒ", 
    "å¼·åˆ¶", "ç›œç”¨", "èª˜æƒ‘","æ€¥åˆ‡", "å‚¬ä¿ƒ"
]

# æ“´å±•è©é¨™æƒ…ç·’é¡åˆ¥ - å—å®³è€…æƒ…ç·’
scam_victim_emotions = [
    "ææ…Œ", "ç„¦æ…®", "ç·Šå¼µ", "å›°æƒ‘", "ç–‘æƒ‘", "ä¸å®‰", "ç„¡åŠ©", "æ‡·ç–‘", 
    "å—é¨™", "å®³æ€•", "å¤±æœ›", "è¢«èƒŒå›", "ç„¡å¥ˆ", "å£“åŠ›", "ææ‡¼", 
    "å¾¬å¾¨", "æ“”å¿ƒ", "æ²®å–ª", "ç¾æ„§", "æ…Œå¼µ", "æ‚”æ¨", "ç–‘æ…®", "å¤±æ•—",
    "è²ªå¿ƒ", "æ¸´æœ›", "è¡å‹•", "æœŸå¾…", "æ€¥åˆ‡", "è¼•ä¿¡"
]


# åŠ è¼‰ BERT æ¨¡å‹å’Œ Tokenizer
class BertForRoleClassification(nn.Module):
    def __init__(self, num_labels):
        super(BertForRoleClassification, self).__init__()
        self.bert = BertForSequenceClassification.from_pretrained("bert-base-chinese", num_labels=num_labels)

    def forward(self, input_ids, attention_mask):
        return self.bert(input_ids=input_ids, attention_mask=attention_mask)

# åŠ è¼‰æ¨¡å‹
def load_model(model_path, device):
    model = BertForRoleClassification(num_labels=2).to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()  # åˆ‡æ›åˆ°è©•ä¼°æ¨¡å¼
    return model

# é æ¸¬å‡½æ•¸
def predict_role(text, model, tokenizer, device):
    encoding = tokenizer(
        text,
        padding="max_length",
        truncation=True,
        max_length=128,
        return_tensors="pt",
    )

    input_ids = encoding["input_ids"].to(device)
    attention_mask = encoding["attention_mask"].to(device)

    with torch.no_grad():
        outputs = model(input_ids, attention_mask)
        logits = outputs.logits
        prediction = torch.argmax(logits, dim=1).item()  # ç²å–é æ¸¬çš„æ¨™ç±¤ï¼ˆ0 æˆ– 1ï¼‰

    label_mapping = {0: "è©é¨™è€…", 1: "å—å®³è€…"}
    return label_mapping.get(prediction, "Unknown")

# æƒ…ç·’åˆ†æ
def analyze_scam_emotion(text, emotion_group):
    result = classifier(text, emotion_group, multi_label=True)

    # å–å¾—åˆ†é¡çµæœï¼Œä¸¦æ’åºå–å¾—å‰å…©å
    sorted_scores = sorted(zip(result["labels"], result["scores"]), key=lambda x: x[1], reverse=True)
    top_two = sorted_scores[:2]

    return {
        "text": text,
        "top_emotions": {label: round(score, 4) for label, score in top_two}  # ä¿ç•™ 4 ä½å°æ•¸
    }

# è™•ç†é•·æ–‡æœ¬ä¸¦åˆ†æ®µé æ¸¬
from collections import defaultdict

import time
import re
from collections import defaultdict

def process_long_text(text, model, tokenizer, device):
    # å…ˆå°‡è¼¸å…¥çš„é•·æ–‡æœ¬åˆ†å‰²æˆå¥å­ï¼ˆæ­¤è™•ç°¡å–®ä»¥å¥è™Ÿç‚ºåˆ†éš”ç¬¦ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­å¯æ ¹æ“šéœ€æ±‚æ”¹é€²åˆ†å‰²è¦å‰‡ï¼‰
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])\s*', text)  # åˆ†éš”ç¬¦ç‚ºï¼šå¥è™Ÿã€å•è™Ÿã€æ„Ÿå˜†è™Ÿå’Œå¾ŒçºŒçš„ç©ºæ ¼

    emotion_scores = defaultdict(float)  # ç”¨ä¾†å­˜å„²æ‰€æœ‰æƒ…ç·’çš„ç´¯è¨ˆåˆ†æ•¸
    results = []
    
    for sentence in sentences:
        if sentence.strip():  # ç¢ºä¿å¥å­ä¸æ˜¯ç©ºç™½
            role = predict_role(sentence.strip(), model, tokenizer, device)
            results.append((sentence.strip(), role))

            print()
            print(f"å¥å­: {sentence} é æ¸¬è§’è‰²: {role}")
            # æ ¹æ“šè§’è‰²é€²è¡Œæƒ…ç·’åˆ†æ
            if role == "è©é¨™è€…":
                emotion_result = analyze_scam_emotion(sentence, scam_perpetrator_emotions)
                print("è©é¨™è€…æƒ…ç·’åˆ†æï¼š", emotion_result)

            elif role == "å—å®³è€…":
                # emotion_result = analyze_scam_emotion(sentence, scam_victim_emotions)
                print("å—å®³è€…")
                emotion_result = {}
            else:
                emotion_result = {}  # å¦‚æœç„¡æ³•è­˜åˆ¥è§’è‰²ï¼Œå°±è·³é

            # å°‡æƒ…ç·’åˆ†æ•¸é€²è¡Œç´¯åŠ 
            if emotion_result.get("top_emotions"):
                for emotion, score in emotion_result["top_emotions"].items():
                    emotion_scores[emotion] += score  # ç´¯è¨ˆæ‰€æœ‰æƒ…ç·’çš„åˆ†æ•¸

    # æ‰¾å‡ºç´¯è¨ˆåˆ†æ•¸æœ€é«˜çš„æƒ…ç·’
    max_emotion = max(emotion_scores, key=emotion_scores.get, default="ç„¡")
    max_score = emotion_scores.get(max_emotion, 0)

    return results, max_emotion, max_score



# äº¤äº’å¼è¼¸å…¥
import time

# äº¤äº’å¼è¼¸å…¥
def interactive_input(text):
    # Step 1: è¨­ç½®è¨­å‚™
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Step 2: åŠ è¼‰åˆ†è©å™¨èˆ‡æ¨¡å‹
    t0 = time.time()
    tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
    model_path = "model/bert_role_classifier.pth"
    model = load_model(model_path, device)
    t1 = time.time()
    print(f"ğŸ”§ æ¨¡å‹èˆ‡åˆ†è©å™¨åŠ è¼‰è€—æ™‚ï¼š{t1 - t0:.4f} ç§’")

    # Step 3: è™•ç†é•·æ–‡æœ¬ä¸¦åˆ†æè§’è‰²èˆ‡æƒ…ç·’
    t2 = time.time()
    roles, max_emotion, max_score = process_long_text(text, model, tokenizer, device)
    t3 = time.time()
    print(f"ğŸ§  é•·æ–‡æœ¬è™•ç†èˆ‡æƒ…ç·’åˆ†æè€—æ™‚ï¼š{t3 - t2:.4f} ç§’")

    # Step 5: é¡¯ç¤ºç´¯ç©æƒ…ç·’çµæœ
    print(f"\nğŸŒŸ ç´¯è¨ˆæƒ…ç·’åˆ†æ•¸ï¼šæœ€é«˜æƒ…ç·’æ˜¯ '{max_emotion}'ï¼Œç¸½åˆ†ï¼š{max_score:.2f}")

    # ç¸½è€—æ™‚
    total_time = t3 - t0
    print(f"\nâ±ï¸ ç¸½è€—æ™‚ï¼š{total_time:.4f} ç§’")

    return max_emotion, max_score


# ä½¿ç”¨ç¯„ä¾‹ï¼š
if __name__ == "__main__":
    user_input = input("è«‹è¼¸å…¥ä¸€æ®µå°è©±æ–‡æœ¬ï¼š")  # ç¤ºä¾‹æ–‡æœ¬ï¼Œå¯ä»¥æ›¿æ¢æˆå®é™…è¾“å…¥
    interactive_input(user_input)